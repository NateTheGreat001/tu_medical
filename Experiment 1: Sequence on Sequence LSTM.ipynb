{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d03f038869731352",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:00.636549376Z",
     "start_time": "2023-10-30T18:13:58.427858801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 19:13:59.093376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-30 19:13:59.753274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from functions import *\n",
    "\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175260a0cd715d73",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cfe5fd621ed9ec",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The original dataset has taxa counts as rows and samples as columns. Since the goal here is to predict taxa counts in the same sample I transpose the original data such that one row represents taxa counts from the same sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6001d8b83f583924",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:00.761445500Z",
     "start_time": "2023-10-30T18:14:00.638150192Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(df_path, index_col=\"Unnamed: 0\").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695f71963d47a010",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:00.772234434Z",
     "start_time": "2023-10-30T18:14:00.761997657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              1050608  130468   3589405  355102   1081058  189592   354275   \\\n",
      "E000823.1.8         0        0        0        0        0        0        0   \n",
      "E000823.2.6         0        0        0        0        0        0        0   \n",
      "E000823.4.0         0        0        0        0        0        0        0   \n",
      "E000823.5.0         0        0        0        0        0        0        0   \n",
      "E000823.5.7         0        0        0        0        0        0        0   \n",
      "...               ...      ...      ...      ...      ...      ...      ...   \n",
      "E014086.30.4        0        0        0        0        0        1       11   \n",
      "E014086.32.4        0        0        0        0        0        0       13   \n",
      "E014086.33.5        0        0        0        0        0        0        0   \n",
      "E014086.34.4        0        0        0        0        0        1        0   \n",
      "E014086.36.0        0        0        0        0        0        0        0   \n",
      "\n",
      "              4327628  326749   183857   ...  317924   4294457  2655741  \\\n",
      "E000823.1.8         0        0        0  ...        0        0        0   \n",
      "E000823.2.6         0        0        0  ...        0        0        0   \n",
      "E000823.4.0         0        0        0  ...        0        0        0   \n",
      "E000823.5.0         0        0        0  ...        0        0        0   \n",
      "E000823.5.7         0        0        0  ...        0        0        0   \n",
      "...               ...      ...      ...  ...      ...      ...      ...   \n",
      "E014086.30.4        0        0        0  ...        1        0        0   \n",
      "E014086.32.4        0        0        0  ...        1        0        0   \n",
      "E014086.33.5        0        0        0  ...        1        0        0   \n",
      "E014086.34.4        0        0        0  ...        0        0        0   \n",
      "E014086.36.0        0        0        0  ...        0        0        0   \n",
      "\n",
      "              858535   186092   299820   225846   4306049  366846   1124370  \n",
      "E000823.1.8         0        0        0        0        0        0        0  \n",
      "E000823.2.6         0        0        0        0        0        0        0  \n",
      "E000823.4.0         0        0        0        1        0        0        0  \n",
      "E000823.5.0         0        0        0        0        0        0        0  \n",
      "E000823.5.7         0        0        0        0        0        0        0  \n",
      "...               ...      ...      ...      ...      ...      ...      ...  \n",
      "E014086.30.4        0        0        0        0        0        0        0  \n",
      "E014086.32.4        0        0        0        0        0        0        0  \n",
      "E014086.33.5        0        0        0        0        0        0        0  \n",
      "E014086.34.4        0        0        0        0        0        0        0  \n",
      "E014086.36.0        0        0        0        0        0        0        0  \n",
      "\n",
      "[521 rows x 7244 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b30ecdf71fb936",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-09T19:12:39.848576469Z",
     "start_time": "2023-10-09T19:12:39.796595664Z"
    },
    "collapsed": false
   },
   "source": [
    "The dataset contains 521 samples of 7244 taxa, most of which are very sparsely populated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6f80ea387a8cff",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:01.812661292Z",
     "start_time": "2023-10-30T18:14:00.768634726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "non_zero_value_pcts = calculate_non_zero_value_percentages(df)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.histplot(non_zero_value_pcts)\n",
    "plt.title(\"Percentages of Non-Zero values across taxa\")\n",
    "plt.xlabel(\"Percentage of Non-Zero Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c7bcc070eac887",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa9c347b4265bda",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:01.945555487Z",
     "start_time": "2023-10-30T18:14:01.814515780Z"
    }
   },
   "outputs": [],
   "source": [
    "df = load_and_merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "694a51b29751a523",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:03.073753926Z",
     "start_time": "2023-10-30T18:14:01.947002882Z"
    }
   },
   "outputs": [],
   "source": [
    "min_non_zero_pct = 0.8\n",
    "window_size = 3\n",
    "sequence_length = 10\n",
    "\n",
    "df = load_and_merge()\n",
    "\n",
    "df = remove_underpopulated_taxa(df, min_non_zero_pct)\n",
    "df = standard_rolling_average(df, window_size)\n",
    "df = feature_wise_scaling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5220c9441ea262a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:03.098395314Z",
     "start_time": "2023-10-30T18:14:03.079318170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               865469   585419   564806   262095   583656   560336   182854  \\\nE000823.4.0  0.002424 0.000379 0.113394 0.034098 0.580222 0.040000 0.193548   \nE000823.5.0  0.000958 0.000632 0.117647 0.038716 0.482914 0.034000 0.219355   \nE000823.5.7  0.000620 0.058665 0.089668 0.081743 0.496305 0.026000 0.122581   \nE000823.6.7  0.159159 0.135397 0.062047 0.098214 0.320627 0.017000 0.154839   \nE000823.8.5  0.158651 0.136450 0.046781 0.093596 0.314938 0.036000 0.129032   \n...               ...      ...      ...      ...      ...      ...      ...   \nE014086.30.4 0.038563 0.005180 0.008506 0.024708 0.274129 0.407000 0.470968   \nE014086.32.4 0.077127 0.006233 0.005103 0.014778 0.395958 0.603000 0.509677   \nE014086.33.5 0.098213 0.005728 0.005238 0.011469 0.403894 0.798000 0.470968   \nE014086.34.4 0.063201 0.001558 0.003760 0.006542 0.405465 0.868000 0.412903   \nE014086.36.0 0.026555 0.000547 0.002462 0.005003 0.243113 0.619000 0.232258   \n\n               581079   559527   513445  ...   312140   484304   301578  \\\nE000823.4.0  0.000211 0.014423 0.152893  ... 0.134670 1.000000 0.169154   \nE000823.5.0  0.000211 0.015839 0.177686  ... 0.131805 0.923267 0.169154   \nE000823.5.7  0.000633 0.017025 0.095041  ... 0.054441 0.834464 0.104478   \nE000823.6.7  0.036920 0.019506 0.070248  ... 0.071633 0.555063 0.119403   \nE000823.8.5  0.036920 0.047941 0.053719  ... 0.051576 0.442354 0.094527   \n...               ...      ...      ...  ...      ...      ...      ...   \nE014086.30.4 0.063080 0.000475 0.380165  ... 0.183381 0.000270 0.358209   \nE014086.32.4 0.088608 0.002027 0.483471  ... 0.530086 0.000231 0.353234   \nE014086.33.5 0.078270 0.002150 0.512397  ... 0.790831 0.000154 0.353234   \nE014086.34.4 0.058228 0.001841 0.471074  ... 1.000000 0.000039 0.353234   \nE014086.36.0 0.031646 0.000597 0.297521  ... 0.710602 0.000000 0.278607   \n\n               577170   193233   196664   583117  subject_id  sampling_day  \\\nE000823.4.0  0.122840 0.040201 0.059699 0.010154     E000823           120   \nE000823.5.0  0.155183 0.035804 0.054162 0.010779     E000823           150   \nE000823.5.7  0.115150 0.034338 0.060045 0.009685     E000823           171   \nE000823.6.7  0.071113 0.021566 0.035127 0.006092     E000823           201   \nE000823.8.5  0.083439 0.050251 0.061602 0.037334     E000823           255   \n...               ...      ...      ...      ...         ...           ...   \nE014086.30.4 0.288137 0.091290 0.127531 0.423113     E014086           912   \nE014086.32.4 0.426464 0.142169 0.345042 0.622876     E014086           972   \nE014086.33.5 0.507480 0.213358 0.537809 0.756436     E014086          1005   \nE014086.34.4 0.571745 0.241625 0.631597 0.749125     E014086          1032   \nE014086.36.0 0.465971 0.217127 0.488320 0.559266     E014086          1080   \n\n              ind_time  \nE000823.4.0   4.000000  \nE000823.5.0   5.000000  \nE000823.5.7   5.700000  \nE000823.6.7   6.700000  \nE000823.8.5   8.500000  \n...                ...  \nE014086.30.4 30.400000  \nE014086.32.4 32.400000  \nE014086.33.5 33.500000  \nE014086.34.4 34.400000  \nE014086.36.0 36.000000  \n\n[519 rows x 41 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>865469</th>\n      <th>585419</th>\n      <th>564806</th>\n      <th>262095</th>\n      <th>583656</th>\n      <th>560336</th>\n      <th>182854</th>\n      <th>581079</th>\n      <th>559527</th>\n      <th>513445</th>\n      <th>...</th>\n      <th>312140</th>\n      <th>484304</th>\n      <th>301578</th>\n      <th>577170</th>\n      <th>193233</th>\n      <th>196664</th>\n      <th>583117</th>\n      <th>subject_id</th>\n      <th>sampling_day</th>\n      <th>ind_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>E000823.4.0</th>\n      <td>0.002424</td>\n      <td>0.000379</td>\n      <td>0.113394</td>\n      <td>0.034098</td>\n      <td>0.580222</td>\n      <td>0.040000</td>\n      <td>0.193548</td>\n      <td>0.000211</td>\n      <td>0.014423</td>\n      <td>0.152893</td>\n      <td>...</td>\n      <td>0.134670</td>\n      <td>1.000000</td>\n      <td>0.169154</td>\n      <td>0.122840</td>\n      <td>0.040201</td>\n      <td>0.059699</td>\n      <td>0.010154</td>\n      <td>E000823</td>\n      <td>120</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>E000823.5.0</th>\n      <td>0.000958</td>\n      <td>0.000632</td>\n      <td>0.117647</td>\n      <td>0.038716</td>\n      <td>0.482914</td>\n      <td>0.034000</td>\n      <td>0.219355</td>\n      <td>0.000211</td>\n      <td>0.015839</td>\n      <td>0.177686</td>\n      <td>...</td>\n      <td>0.131805</td>\n      <td>0.923267</td>\n      <td>0.169154</td>\n      <td>0.155183</td>\n      <td>0.035804</td>\n      <td>0.054162</td>\n      <td>0.010779</td>\n      <td>E000823</td>\n      <td>150</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>E000823.5.7</th>\n      <td>0.000620</td>\n      <td>0.058665</td>\n      <td>0.089668</td>\n      <td>0.081743</td>\n      <td>0.496305</td>\n      <td>0.026000</td>\n      <td>0.122581</td>\n      <td>0.000633</td>\n      <td>0.017025</td>\n      <td>0.095041</td>\n      <td>...</td>\n      <td>0.054441</td>\n      <td>0.834464</td>\n      <td>0.104478</td>\n      <td>0.115150</td>\n      <td>0.034338</td>\n      <td>0.060045</td>\n      <td>0.009685</td>\n      <td>E000823</td>\n      <td>171</td>\n      <td>5.700000</td>\n    </tr>\n    <tr>\n      <th>E000823.6.7</th>\n      <td>0.159159</td>\n      <td>0.135397</td>\n      <td>0.062047</td>\n      <td>0.098214</td>\n      <td>0.320627</td>\n      <td>0.017000</td>\n      <td>0.154839</td>\n      <td>0.036920</td>\n      <td>0.019506</td>\n      <td>0.070248</td>\n      <td>...</td>\n      <td>0.071633</td>\n      <td>0.555063</td>\n      <td>0.119403</td>\n      <td>0.071113</td>\n      <td>0.021566</td>\n      <td>0.035127</td>\n      <td>0.006092</td>\n      <td>E000823</td>\n      <td>201</td>\n      <td>6.700000</td>\n    </tr>\n    <tr>\n      <th>E000823.8.5</th>\n      <td>0.158651</td>\n      <td>0.136450</td>\n      <td>0.046781</td>\n      <td>0.093596</td>\n      <td>0.314938</td>\n      <td>0.036000</td>\n      <td>0.129032</td>\n      <td>0.036920</td>\n      <td>0.047941</td>\n      <td>0.053719</td>\n      <td>...</td>\n      <td>0.051576</td>\n      <td>0.442354</td>\n      <td>0.094527</td>\n      <td>0.083439</td>\n      <td>0.050251</td>\n      <td>0.061602</td>\n      <td>0.037334</td>\n      <td>E000823</td>\n      <td>255</td>\n      <td>8.500000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>E014086.30.4</th>\n      <td>0.038563</td>\n      <td>0.005180</td>\n      <td>0.008506</td>\n      <td>0.024708</td>\n      <td>0.274129</td>\n      <td>0.407000</td>\n      <td>0.470968</td>\n      <td>0.063080</td>\n      <td>0.000475</td>\n      <td>0.380165</td>\n      <td>...</td>\n      <td>0.183381</td>\n      <td>0.000270</td>\n      <td>0.358209</td>\n      <td>0.288137</td>\n      <td>0.091290</td>\n      <td>0.127531</td>\n      <td>0.423113</td>\n      <td>E014086</td>\n      <td>912</td>\n      <td>30.400000</td>\n    </tr>\n    <tr>\n      <th>E014086.32.4</th>\n      <td>0.077127</td>\n      <td>0.006233</td>\n      <td>0.005103</td>\n      <td>0.014778</td>\n      <td>0.395958</td>\n      <td>0.603000</td>\n      <td>0.509677</td>\n      <td>0.088608</td>\n      <td>0.002027</td>\n      <td>0.483471</td>\n      <td>...</td>\n      <td>0.530086</td>\n      <td>0.000231</td>\n      <td>0.353234</td>\n      <td>0.426464</td>\n      <td>0.142169</td>\n      <td>0.345042</td>\n      <td>0.622876</td>\n      <td>E014086</td>\n      <td>972</td>\n      <td>32.400000</td>\n    </tr>\n    <tr>\n      <th>E014086.33.5</th>\n      <td>0.098213</td>\n      <td>0.005728</td>\n      <td>0.005238</td>\n      <td>0.011469</td>\n      <td>0.403894</td>\n      <td>0.798000</td>\n      <td>0.470968</td>\n      <td>0.078270</td>\n      <td>0.002150</td>\n      <td>0.512397</td>\n      <td>...</td>\n      <td>0.790831</td>\n      <td>0.000154</td>\n      <td>0.353234</td>\n      <td>0.507480</td>\n      <td>0.213358</td>\n      <td>0.537809</td>\n      <td>0.756436</td>\n      <td>E014086</td>\n      <td>1005</td>\n      <td>33.500000</td>\n    </tr>\n    <tr>\n      <th>E014086.34.4</th>\n      <td>0.063201</td>\n      <td>0.001558</td>\n      <td>0.003760</td>\n      <td>0.006542</td>\n      <td>0.405465</td>\n      <td>0.868000</td>\n      <td>0.412903</td>\n      <td>0.058228</td>\n      <td>0.001841</td>\n      <td>0.471074</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000039</td>\n      <td>0.353234</td>\n      <td>0.571745</td>\n      <td>0.241625</td>\n      <td>0.631597</td>\n      <td>0.749125</td>\n      <td>E014086</td>\n      <td>1032</td>\n      <td>34.400000</td>\n    </tr>\n    <tr>\n      <th>E014086.36.0</th>\n      <td>0.026555</td>\n      <td>0.000547</td>\n      <td>0.002462</td>\n      <td>0.005003</td>\n      <td>0.243113</td>\n      <td>0.619000</td>\n      <td>0.232258</td>\n      <td>0.031646</td>\n      <td>0.000597</td>\n      <td>0.297521</td>\n      <td>...</td>\n      <td>0.710602</td>\n      <td>0.000000</td>\n      <td>0.278607</td>\n      <td>0.465971</td>\n      <td>0.217127</td>\n      <td>0.488320</td>\n      <td>0.559266</td>\n      <td>E014086</td>\n      <td>1080</td>\n      <td>36.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>519 rows Ã— 41 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9acc32afab525",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Features and tergets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8ff0595585d8cc2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:03.283026670Z",
     "start_time": "2023-10-30T18:14:03.087063390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test subjects are ['E003188' 'E001958' 'E014086']\n"
     ]
    }
   ],
   "source": [
    "number_test_sequences = 3\n",
    "\n",
    "train_feats, train_targets, test_feats, test_targets, test_subjects = feats_and_targets(df, seq_length=sequence_length, n_test_seq=number_test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a451234a7bd30a15",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:03.287039211Z",
     "start_time": "2023-10-30T18:14:03.282228747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265 265\n"
     ]
    }
   ],
   "source": [
    "print(len(train_feats), len(train_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50c37c13cb2fbe6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da12162a0ccf320d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:04.514721477Z",
     "start_time": "2023-10-30T18:14:03.288014822Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 19:14:03.352406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-30 19:14:03.368595: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-30 19:14:03.368850: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-30 19:14:03.375859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-30 19:14:03.376147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-30 19:14:03.376325: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-30 19:14:03.447582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-30 19:14:03.448101: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-30 19:14:03.448284: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-10-30 19:14:03.448430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1042 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Ti, pci bus id: 0000:61:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1024)              4362240   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2048)              2099200   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 40)                81960     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6543400 (24.96 MB)\n",
      "Trainable params: 6543400 (24.96 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reg = 1e-12\n",
    "loss=mae_ignore_zeros(false_positives_penalty_factor=0.3)\n",
    "\n",
    "n_feats = len(df.columns) - 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(sequence_length, n_feats)))\n",
    "model.add(keras.layers.LSTM(1024, return_sequences=False, activation='relu'))\n",
    "model.add(keras.layers.Dense(2048, activation=\"tanh\", kernel_regularizer=l1_l2(reg)))\n",
    "model.add(keras.layers.Dense(n_feats, activation=\"relu\", kernel_regularizer=l1_l2(reg)))\n",
    "\n",
    "model.compile(optimizer=\"Adam\", loss=loss, metrics=[\"mae\", \"mape\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1324a90e10b9d19c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Training and Validation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "953f4711-2b7b-422a-890c-4431dfbc72ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ea327132225fb48",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:19.579166990Z",
     "start_time": "2023-10-30T18:14:04.510640246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-30 19:14:05.435319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-10-30 19:14:05.459729: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f3bac0316f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-10-30 19:14:05.459755: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2023-10-30 19:14:05.464203: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-30 19:14:05.475190: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-10-30 19:14:05.573864: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 41ms/step - loss: 1861.2865 - mae: 18.2312 - mape: 962995.2500 - val_loss: 1728.6356 - val_mae: 16.9465 - val_mape: 96.5885\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1767.0151 - mae: 17.3715 - mape: 96.7674 - val_loss: 1683.0000 - val_mae: 16.5267 - val_mape: 96.6626\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1723.0253 - mae: 16.9610 - mape: 96.7521 - val_loss: 1639.5730 - val_mae: 16.1160 - val_mape: 96.5592\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1680.8492 - mae: 16.5588 - mape: 96.6544 - val_loss: 1597.2675 - val_mae: 15.7080 - val_mape: 96.4216\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1639.6283 - mae: 16.1605 - mape: 96.5948 - val_loss: 1558.2434 - val_mae: 15.3276 - val_mape: 96.4006\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1601.2627 - mae: 15.7802 - mape: 96.5305 - val_loss: 1520.1604 - val_mae: 14.9541 - val_mape: 96.3284\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1562.8474 - mae: 15.4029 - mape: 313.3947 - val_loss: 1480.4974 - val_mae: 14.5641 - val_mape: 96.3762\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1520.7429 - mae: 14.9943 - mape: 96.4685 - val_loss: 1438.2742 - val_mae: 14.1485 - val_mape: 96.2562\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1479.2874 - mae: 14.5864 - mape: 142.0200 - val_loss: 1400.1337 - val_mae: 13.7730 - val_mape: 270.5423\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1438.1619 - mae: 14.1778 - mape: 205.4761 - val_loss: 1354.4700 - val_mae: 13.3232 - val_mape: 96.1012\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1395.7136 - mae: 13.7612 - mape: 96.2590 - val_loss: 1313.1630 - val_mae: 12.9162 - val_mape: 96.0750\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1354.1848 - mae: 13.3481 - mape: 96.1809 - val_loss: 1270.8685 - val_mae: 12.4995 - val_mape: 95.9709\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1312.7227 - mae: 12.9343 - mape: 96.1190 - val_loss: 1229.1798 - val_mae: 12.0887 - val_mape: 95.9310\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1270.5221 - mae: 12.5221 - mape: 96.0723 - val_loss: 1187.2838 - val_mae: 11.6758 - val_mape: 95.8650\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1229.0892 - mae: 12.1099 - mape: 96.0182 - val_loss: 1145.5887 - val_mae: 11.2648 - val_mape: 95.8114\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1187.2250 - mae: 11.6986 - mape: 95.9215 - val_loss: 1103.2550 - val_mae: 10.8474 - val_mape: 95.6821\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1145.3552 - mae: 11.2848 - mape: 95.8805 - val_loss: 1062.5378 - val_mae: 10.4460 - val_mape: 95.7266\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1103.6055 - mae: 10.8731 - mape: 95.8324 - val_loss: 1019.7180 - val_mae: 10.0238 - val_mape: 95.5576\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1061.8585 - mae: 10.4639 - mape: 95.7211 - val_loss: 978.0541 - val_mae: 9.6129 - val_mape: 95.5058\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1020.0792 - mae: 10.0511 - mape: 95.7138 - val_loss: 937.2177 - val_mae: 9.2102 - val_mape: 95.5265\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 978.3131 - mae: 9.6368 - mape: 95.6251 - val_loss: 894.4453 - val_mae: 8.7883 - val_mape: 95.3529\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: nan - mae: 9.2282 - mape: 95.5545 - val_loss: 853.0763 - val_mae: 8.3802 - val_mape: 95.3357\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 897.3021 - mae: 8.8327 - mape: 95.5123 - val_loss: 835.2523 - val_mae: 8.2042 - val_mape: 95.2616\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 875.6652 - mae: 8.6197 - mape: 95.4761 - val_loss: 789.2460 - val_mae: 7.7503 - val_mape: 95.2362\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 839.8865 - mae: 8.2645 - mape: 95.4146 - val_loss: 765.8373 - val_mae: 7.5192 - val_mape: 95.1550\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 819.3881 - mae: 8.0618 - mape: 95.3914 - val_loss: 747.1970 - val_mae: 7.3350 - val_mape: 95.2417\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 808.4522 - mae: 7.9565 - mape: 95.3876 - val_loss: 739.6088 - val_mae: 7.2598 - val_mape: 95.1350\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 811.1217 - mae: 7.9774 - mape: 95.3557 - val_loss: 743.8229 - val_mae: 7.3009 - val_mape: 174.3841\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 802.2799 - mae: 7.8927 - mape: 103176.5781 - val_loss: 727.0650 - val_mae: 7.1352 - val_mape: 95.1547\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 788.5427 - mae: 7.7543 - mape: 95.3331 - val_loss: 713.7512 - val_mae: 7.0035 - val_mape: 95.1064\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 775.9492 - mae: 7.6332 - mape: 95.3623 - val_loss: 701.1351 - val_mae: 6.8787 - val_mape: 95.1799\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 759.0201 - mae: 7.4647 - mape: 95.3128 - val_loss: 680.9610 - val_mae: 6.6794 - val_mape: 95.0316\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: nan - mae: 7.2888 - mape: 95.2785 - val_loss: 665.6888 - val_mae: 6.5284 - val_mape: 95.0531\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: nan - mae: 7.3324 - mape: 3217.5632 - val_loss: 668.5278 - val_mae: 6.5559 - val_mape: 95.0622\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 724.3408 - mae: 7.1239 - mape: 95.2675 - val_loss: 644.0037 - val_mae: 6.3136 - val_mape: 95.0278\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 697.1876 - mae: 6.8510 - mape: 95.2111 - val_loss: 619.0039 - val_mae: 6.0667 - val_mape: 94.9449\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 673.0256 - mae: 6.6125 - mape: 95.1884 - val_loss: 600.8489 - val_mae: 5.8873 - val_mape: 95.0084\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 657.6301 - mae: 6.4594 - mape: 95.1983 - val_loss: 585.5130 - val_mae: 5.7357 - val_mape: 94.9228\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 641.3901 - mae: 6.3005 - mape: 95.1397 - val_loss: 568.1931 - val_mae: 5.5646 - val_mape: 94.9119\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 623.8226 - mae: 6.1267 - mape: 95.1502 - val_loss: 555.2283 - val_mae: 5.4364 - val_mape: 94.9284\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 608.0852 - mae: 5.9666 - mape: 95.1295 - val_loss: 544.1755 - val_mae: 5.3271 - val_mape: 94.9081\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 601.2102 - mae: 5.9016 - mape: 95.1226 - val_loss: 540.7030 - val_mae: 5.2924 - val_mape: 94.9014\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 593.6289 - mae: 5.8237 - mape: 95.1172 - val_loss: 526.6755 - val_mae: 5.1538 - val_mape: 94.8863\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 582.2960 - mae: 5.7105 - mape: 43989.8789 - val_loss: 519.1171 - val_mae: 5.0789 - val_mape: 94.8753\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 575.2679 - mae: 5.6434 - mape: 95.1430 - val_loss: 516.1929 - val_mae: 5.0496 - val_mape: 94.9361\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 566.3834 - mae: 5.5565 - mape: 95.1024 - val_loss: 510.7512 - val_mae: 4.9956 - val_mape: 94.8401\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 557.6250 - mae: 5.4671 - mape: 95.0490 - val_loss: 503.9652 - val_mae: 4.9284 - val_mape: 94.8234\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 546.1574 - mae: 5.3543 - mape: 95.0793 - val_loss: 501.8210 - val_mae: 4.9069 - val_mape: 94.9623\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 538.1827 - mae: 5.2760 - mape: 95.0831 - val_loss: 497.9453 - val_mae: 4.8683 - val_mape: 94.8318\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 529.8987 - mae: 5.1927 - mape: 95.0308 - val_loss: 495.4289 - val_mae: 4.8432 - val_mape: 94.8872\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 522.2115 - mae: 5.1173 - mape: 95.1013 - val_loss: 494.1577 - val_mae: 4.8303 - val_mape: 94.9472\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 515.9317 - mae: 5.0570 - mape: 95.0490 - val_loss: 490.4845 - val_mae: 4.7938 - val_mape: 94.8226\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 510.8801 - mae: 5.0031 - mape: 95.0427 - val_loss: 490.5010 - val_mae: 4.7936 - val_mape: 94.9689\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 506.8562 - mae: 4.9654 - mape: 95.0806 - val_loss: 488.1217 - val_mae: 4.7699 - val_mape: 94.8689\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 502.6631 - mae: 4.9204 - mape: 95.0199 - val_loss: 486.6218 - val_mae: 4.7549 - val_mape: 94.8950\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 499.9817 - mae: 4.8956 - mape: 95.0665 - val_loss: 485.1051 - val_mae: 4.7396 - val_mape: 94.9290\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 495.3996 - mae: 4.8485 - mape: 95.0321 - val_loss: 482.9102 - val_mae: 4.7177 - val_mape: 94.8537\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 492.3720 - mae: 4.8216 - mape: 95.0142 - val_loss: 482.0132 - val_mae: 4.7087 - val_mape: 94.9407\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 490.0618 - mae: 4.7981 - mape: 95.1045 - val_loss: 481.5348 - val_mae: 4.7037 - val_mape: 94.9316\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 488.8635 - mae: 4.7848 - mape: 95.0207 - val_loss: 480.7071 - val_mae: 4.6953 - val_mape: 94.8225\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 511.5273 - mae: 5.0076 - mape: 80204.5000 - val_loss: 570.4877 - val_mae: 5.5800 - val_mape: 94.3835\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 740.4931 - mae: 7.2705 - mape: 11078.9307 - val_loss: 719.7681 - val_mae: 7.0507 - val_mape: 95.1137\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 871.3494 - mae: 8.5500 - mape: 317541.6875 - val_loss: 824.4899 - val_mae: 8.0297 - val_mape: 2655078.5000\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 866.9778 - mae: 8.5147 - mape: 300728.0312 - val_loss: 763.9527 - val_mae: 7.4844 - val_mape: 95.2351\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 829.1882 - mae: 8.1445 - mape: 95.3962 - val_loss: 735.0228 - val_mae: 7.1983 - val_mape: 95.1559\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 794.1382 - mae: 7.7986 - mape: 95.3559 - val_loss: 708.5885 - val_mae: 6.9370 - val_mape: 95.1438\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 755.5946 - mae: 7.4178 - mape: 95.3052 - val_loss: 672.2960 - val_mae: 6.5785 - val_mape: 95.0225\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 721.9678 - mae: 7.0873 - mape: 95.2481 - val_loss: 637.7545 - val_mae: 6.2374 - val_mape: 95.0059\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 677.5298 - mae: 6.6431 - mape: 95.2180 - val_loss: 625.0384 - val_mae: 6.1113 - val_mape: 94.9241\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 685.7976 - mae: 6.7238 - mape: 95.1768 - val_loss: 616.4944 - val_mae: 6.0264 - val_mape: 94.9541\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 662.1801 - mae: 6.4775 - mape: 557377.7500 - val_loss: 619.4809 - val_mae: 6.0552 - val_mape: 95.0270\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 682.2124 - mae: 6.6896 - mape: 248.4592 - val_loss: 627.0726 - val_mae: 6.1294 - val_mape: 94.9095\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 673.3732 - mae: 6.5983 - mape: 95.2231 - val_loss: 596.8912 - val_mae: 5.8312 - val_mape: 95.0745\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 649.3004 - mae: 6.3608 - mape: 95.1893 - val_loss: 573.0226 - val_mae: 5.5952 - val_mape: 94.8955\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 622.7014 - mae: 6.0981 - mape: 95.1379 - val_loss: 547.2603 - val_mae: 5.3407 - val_mape: 94.9374\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 596.4592 - mae: 5.8377 - mape: 95.1189 - val_loss: 535.3314 - val_mae: 5.2225 - val_mape: 94.8748\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 594.1340 - mae: 5.8135 - mape: 95.1180 - val_loss: 533.1544 - val_mae: 5.2005 - val_mape: 94.8859\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 588.2859 - mae: 5.7569 - mape: 95.0935 - val_loss: 521.9697 - val_mae: 5.0897 - val_mape: 94.8684\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 574.6424 - mae: 5.6188 - mape: 95.0839 - val_loss: 513.5431 - val_mae: 5.0061 - val_mape: 94.8794\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 560.4597 - mae: 5.4811 - mape: 95.0945 - val_loss: 506.7186 - val_mae: 4.9383 - val_mape: 94.8865\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 547.6105 - mae: 5.3527 - mape: 14574.2295 - val_loss: 502.1247 - val_mae: 4.8926 - val_mape: 94.8654\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 540.0601 - mae: 5.2764 - mape: 95.0771 - val_loss: 500.1094 - val_mae: 4.8722 - val_mape: 94.8955\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 529.9246 - mae: 5.1786 - mape: 95.0437 - val_loss: 496.4785 - val_mae: 4.8359 - val_mape: 94.8582\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 520.5635 - mae: 5.0844 - mape: 95.0539 - val_loss: 493.3744 - val_mae: 4.8048 - val_mape: 94.9006\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 511.2833 - mae: 4.9911 - mape: 95.0564 - val_loss: 489.5067 - val_mae: 4.7663 - val_mape: 94.8894\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 502.9155 - mae: 4.9068 - mape: 95.0368 - val_loss: 486.6790 - val_mae: 4.7380 - val_mape: 94.8983\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 495.7551 - mae: 4.8364 - mape: 95.0478 - val_loss: 483.6499 - val_mae: 4.7078 - val_mape: 94.9047\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 19ms/step - loss: nan - mae: 4.7853 - mape: 95.0271 - val_loss: 482.7831 - val_mae: 4.6990 - val_mape: 94.8840\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 487.3126 - mae: 4.7571 - mape: 95.0593 - val_loss: 482.8422 - val_mae: 4.6993 - val_mape: 94.8883\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 487.3524 - mae: 4.7532 - mape: 95.0198 - val_loss: 482.7855 - val_mae: 4.6985 - val_mape: 94.8782\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 486.8584 - mae: 4.7480 - mape: 95.0542 - val_loss: 483.5680 - val_mae: 4.7059 - val_mape: 94.9598\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 483.7378 - mae: 4.7155 - mape: 95.0429 - val_loss: 482.6711 - val_mae: 4.6969 - val_mape: 94.8668\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 482.4716 - mae: 4.7040 - mape: 95.0795 - val_loss: 483.2734 - val_mae: 4.7025 - val_mape: 94.9385\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 479.5647 - mae: 4.6746 - mape: 95.0106 - val_loss: 482.3131 - val_mae: 4.6929 - val_mape: 94.8334\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 480.4461 - mae: 4.6833 - mape: 95.0568 - val_loss: 484.1322 - val_mae: 4.7106 - val_mape: 95.0050\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 481.0012 - mae: 4.6894 - mape: 95.0498 - val_loss: 482.8512 - val_mae: 4.6978 - val_mape: 94.8835\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 479.8259 - mae: 4.6787 - mape: 95.0647 - val_loss: 483.7016 - val_mae: 4.7059 - val_mape: 94.9700\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 477.8849 - mae: 4.6580 - mape: 95.0315 - val_loss: 482.9128 - val_mae: 4.6979 - val_mape: 94.8917\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 475.6985 - mae: 4.6358 - mape: 95.0253 - val_loss: 483.2861 - val_mae: 4.7014 - val_mape: 94.9397\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 474.5424 - mae: 4.6231 - mape: 95.0645 - val_loss: 483.2882 - val_mae: 4.7012 - val_mape: 94.9401\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7f3e7fe17940>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats = np.asarray(train_feats)\n",
    "\n",
    "model.fit(x=train_feats, y=train_targets, validation_split=0.05, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['E003188', 'E001958', 'E014086'], dtype=object)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_subjects"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:19.619958761Z",
     "start_time": "2023-10-30T18:14:19.577605938Z"
    }
   },
   "id": "c66e659e09a8929c"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def fetch_subject_y_true_and_y_pred(test_subjects, model, df, target_subject_idx, test_feats, test_targets):\n",
    "    \n",
    "    cols = list(df.columns)[:-1]\n",
    "    \n",
    "    target_subject = test_subjects[target_subject_idx]\n",
    "\n",
    "    test_subject_feats = np.asarray(test_feats[target_subject])\n",
    "    test_subject_targets_df = pd.concat(test_targets[target_subject], axis=1).T\n",
    "    \n",
    "    test_subject_targets_df.columns = cols\n",
    "    test_subject_y_pred = model.predict(test_subject_feats)\n",
    "    \n",
    "    test_subject_y_pred_df = pd.DataFrame(test_subject_y_pred)\n",
    "    test_subject_y_pred_df.columns = cols\n",
    "    test_subject_y_pred_df.index = test_subject_targets_df.index\n",
    "\n",
    "    return test_subject_targets_df, test_subject_y_pred_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:52.114734099Z",
     "start_time": "2023-10-30T18:14:52.086096019Z"
    }
   },
   "id": "208997b6332bfc05"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 108ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "               865469   585419   564806   262095   583656   560336   182854  \\\nE003188.11.6 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.12.6 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.14.4 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.14.9 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.15.7 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.16.5 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.17.4 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.18.9 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.20.0 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.21.1 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.21.9 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.22.9 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.24.2 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.24.8 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.25.6 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.27.6 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.28.9 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.30.0 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.31.7 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \nE003188.34.0 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000   \n\n               581079   559527   513445  ...  3426658   312140   484304  \\\nE003188.11.6 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.12.6 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.14.4 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.14.9 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.15.7 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.16.5 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.17.4 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.18.9 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.20.0 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.21.1 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.21.9 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.22.9 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.24.2 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.24.8 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.25.6 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.27.6 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.28.9 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.30.0 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.31.7 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \nE003188.34.0 0.000000 0.000000 0.000000  ... 0.000000 0.000000 0.000000   \n\n               301578   577170   193233   196664   583117  subject_id  \\\nE003188.11.6 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.12.6 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.14.4 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.14.9 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.15.7 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.16.5 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.17.4 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.18.9 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.20.0 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.21.1 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.21.9 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.22.9 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.24.2 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.24.8 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.25.6 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.27.6 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.28.9 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.30.0 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.31.7 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \nE003188.34.0 0.000000 0.000000 0.000000 0.000000 0.000000  654.499939   \n\n              sampling_day  \nE003188.11.6     23.781210  \nE003188.12.6     23.781210  \nE003188.14.4     23.781210  \nE003188.14.9     23.781210  \nE003188.15.7     23.781210  \nE003188.16.5     23.781210  \nE003188.17.4     23.781210  \nE003188.18.9     23.781210  \nE003188.20.0     23.781210  \nE003188.21.1     23.781210  \nE003188.21.9     23.781210  \nE003188.22.9     23.781210  \nE003188.24.2     23.781210  \nE003188.24.8     23.781210  \nE003188.25.6     23.781210  \nE003188.27.6     23.781210  \nE003188.28.9     23.781210  \nE003188.30.0     23.781210  \nE003188.31.7     23.781210  \nE003188.34.0     23.781210  \n\n[20 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>865469</th>\n      <th>585419</th>\n      <th>564806</th>\n      <th>262095</th>\n      <th>583656</th>\n      <th>560336</th>\n      <th>182854</th>\n      <th>581079</th>\n      <th>559527</th>\n      <th>513445</th>\n      <th>...</th>\n      <th>3426658</th>\n      <th>312140</th>\n      <th>484304</th>\n      <th>301578</th>\n      <th>577170</th>\n      <th>193233</th>\n      <th>196664</th>\n      <th>583117</th>\n      <th>subject_id</th>\n      <th>sampling_day</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>E003188.11.6</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.12.6</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.14.4</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.14.9</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.15.7</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.16.5</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.17.4</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.18.9</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.20.0</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.21.1</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.21.9</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.22.9</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.24.2</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.24.8</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.25.6</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.27.6</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.28.9</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.30.0</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.31.7</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n    <tr>\n      <th>E003188.34.0</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>654.499939</td>\n      <td>23.781210</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows Ã— 40 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_subject_idx = 0\n",
    "target_subject = test_subjects[target_subject_idx]\n",
    "\n",
    "test_subject_targets_df, test_subject_y_pred_df = fetch_subject_y_true_and_y_pred(test_subjects, model, df, target_subject_idx, test_feats, test_targets)\n",
    "\n",
    "test_subject_y_pred_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:52.876386574Z",
     "start_time": "2023-10-30T18:14:52.718411899Z"
    }
   },
   "id": "3023efa746fb9d6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Usually at least some of the taxa are not predictable by a model. Then it returns zeros for their entire sequence"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f65c5aad6156d72"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "non_predicted_taxa = [col for col in test_subject_y_pred_df.columns if all(test_subject_y_pred_df[col] == 0.0)]\n",
    "n_non_predicted_taxa = len(non_predicted_taxa)\n",
    "\n",
    "print(f\"Total taxa not predicted: {non_predicted_taxa}, {(n_non_predicted_taxa/len(test_subject_targets_df.columns)) * 100}% of all taxa\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:21.898166250Z",
     "start_time": "2023-10-30T18:14:21.897499104Z"
    }
   },
   "id": "45d12565b8f197d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next section allows to examine individual true and predicted sequences"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "379c23402fd88e16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41150241c580c1e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.899869981Z"
    }
   },
   "outputs": [],
   "source": [
    "target_taxa = 865469\n",
    "target_subject_idx = 0\n",
    "\n",
    "target_subject = test_subjects[target_subject_idx]\n",
    "\n",
    "true_sequence = test_subject_targets_df[target_taxa].reset_index(drop=True)\n",
    "pred_sequence = test_subject_y_pred_df[target_taxa].reset_index(drop=True)\n",
    "\n",
    "sequence_comparisson_graphs(true_sequence, pred_sequence, target_taxa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ce19435129b8d9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now I look at the performance across different sequences and test subjects. Errors are calculated individually by test subjects and then averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50df804b56c76bf4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:14:21.902095793Z",
     "start_time": "2023-10-30T18:14:21.901654255Z"
    }
   },
   "outputs": [],
   "source": [
    "subjects_error_dfs = []\n",
    "for target_subject_idx in range(len(test_subjects)):\n",
    "    \n",
    "    test_subject_targets_df, test_subject_y_pred_df = fetch_subject_y_true_and_y_pred(test_subjects, model, df, target_subject_idx, test_feats, test_targets, experiment_id=1)\n",
    "\n",
    "    errors_df = calculate_percentage_errors(test_subject_y_pred_df, test_subject_targets_df)\n",
    "    subjects_error_dfs.append(errors_df)\n",
    "    \n",
    "errors_df = pd.concat(subjects_error_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9dc249543eab2f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.903025176Z"
    }
   },
   "outputs": [],
   "source": [
    "percentile_graph(errors_df, \"accross all taxa LSTM SEQUENCE ON SEQUENCE\", y_top_lim=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ec0220b0742aa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Same graph, but only for those taxa that are not all predicted zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3703e881383a35f0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.904440640Z"
    }
   },
   "outputs": [],
   "source": [
    "only_predicted_taxa = test_subject_y_pred_df.columns[~(test_subject_y_pred_df.columns.isin(non_predicted_taxa))].drop(['subject_id', 'sampling_day'])\n",
    "only_predicted_errors = errors_df[only_predicted_taxa]\n",
    "only_predicted_errors.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df6e1c13eff18b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.905811220Z"
    }
   },
   "outputs": [],
   "source": [
    "percentile_graph(only_predicted_errors, \"accross successfully predicted taxa\", y_top_lim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(only_predicted_errors.median().clip(0, 1))\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.906949159Z"
    }
   },
   "id": "7ec77c8a605d5ab9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Errors versus feature populations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58984876fccd6166"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "population_rates = calculate_non_zero_value_percentages(df).drop(['subject_id', 'sampling_day'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.931371973Z"
    }
   },
   "id": "fce77983aaf13c6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "What are the average population rates in the taxa that are predicted by this model compared to the ones that arent?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96e2a49f67533f88"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "population_rates[non_predicted_taxa].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.931555871Z"
    }
   },
   "id": "c46df53c2d5ca7b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "population_rates[only_predicted_taxa].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.931592842Z"
    }
   },
   "id": "959bdfd0589a08e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Among the predicted taxa, is the median error somehow related to the population rate?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d607bacc75c623"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "only_predicted_errors.median()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.931626165Z"
    }
   },
   "id": "4b82995334c967c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "median_errors_by_population_rate(df, only_predicted_errors, only_predicted_taxa)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.931659518Z"
    }
   },
   "id": "57c7104ad2f8f1f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:14:21.931694895Z"
    }
   },
   "id": "6e631b4cbf2f71af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
