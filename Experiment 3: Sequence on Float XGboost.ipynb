{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T18:18:55.162061857Z",
     "start_time": "2023-10-30T18:18:51.469587941Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "2023-10-30 19:18:53.857996: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-30 19:18:54.709716: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import evalml\n",
    "\n",
    "from functions import *\n",
    "\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f766d8390afa45e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef18d46576f78b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T18:18:56.291812714Z",
     "start_time": "2023-10-30T18:18:55.163946533Z"
    }
   },
   "outputs": [],
   "source": [
    "min_non_zero_pct = 0.5\n",
    "window_size = 3\n",
    "sequence_length = 10\n",
    "number_test_sequences = 3\n",
    "\n",
    "df = load_and_merge()\n",
    "df = remove_underpopulated_taxa(df, min_non_zero_pct)\n",
    "df = standard_rolling_average(df, window_size)\n",
    "df = feature_wise_scaling(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9e85a63e727f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T18:18:56.310682299Z",
     "start_time": "2023-10-30T18:18:56.296228270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               659361   364179  3439402   181155   302746  4473763   175535  \\\nE000823.4.0  0.000000 0.000160 0.288889 0.000000 0.000000 0.242718 0.010256   \nE000823.5.0  0.000000 0.000160 0.200000 0.000000 0.000000 0.199029 0.007692   \nE000823.5.7  0.000000 0.000180 0.200000 0.003724 0.000000 0.228155 0.007692   \nE000823.6.7  0.065636 0.000160 0.088889 0.016139 0.000000 0.121359 0.002564   \nE000823.8.5  0.065636 0.000220 0.177778 0.017381 0.000000 0.490291 0.020513   \n...               ...      ...      ...      ...      ...      ...      ...   \nE014086.30.4 0.060355 0.080890 0.288889 0.007449 0.044379 0.111650 0.025641   \nE014086.32.4 0.060355 0.120524 0.622222 0.010552 0.077663 0.194175 0.071795   \nE014086.33.5 0.051679 0.141802 1.000000 0.011173 0.161243 0.436893 0.074359   \nE014086.34.4 0.021124 0.127490 0.977778 0.004345 0.160503 0.572816 0.071795   \nE014086.36.0 0.010939 0.087755 0.755556 0.001862 0.130917 0.563107 0.023077   \n\n              3887769   585227   189384  ...  3304236   584137   193233  \\\nE000823.4.0  0.190476 0.000000 0.100671  ... 0.029412 0.000000 0.040201   \nE000823.5.0  0.119048 0.000000 0.120805  ... 0.117647 0.000000 0.035804   \nE000823.5.7  0.023810 0.000000 0.053691  ... 0.117647 0.000000 0.034338   \nE000823.6.7  0.023810 0.000000 0.080537  ... 0.205882 0.000085 0.021566   \nE000823.8.5  0.071429 0.000000 0.053691  ... 0.176471 0.000085 0.050251   \n...               ...      ...      ...  ...      ...      ...      ...   \nE014086.30.4 0.476190 0.479017 0.503356  ... 0.470588 0.055292 0.091290   \nE014086.32.4 0.404762 0.880928 0.711409  ... 0.441176 0.071990 0.142169   \nE014086.33.5 0.619048 0.849198 0.906040  ... 0.264706 0.057024 0.213358   \nE014086.34.4 0.571429 0.761174 0.899329  ... 0.294118 0.037543 0.241625   \nE014086.36.0 0.523810 0.295462 0.570470  ... 0.352941 0.008463 0.217127   \n\n              4334711   196664   583117   354850  subject_id  sampling_day  \\\nE000823.4.0  0.455696 0.059699 0.010154 0.064039     E000823           120   \nE000823.5.0  0.398734 0.054162 0.010779 0.029557     E000823           150   \nE000823.5.7  0.518987 0.060045 0.009685 0.019704     E000823           171   \nE000823.6.7  0.386076 0.035127 0.006092 0.000000     E000823           201   \nE000823.8.5  0.386076 0.061602 0.037334 0.000000     E000823           255   \n...               ...      ...      ...      ...         ...           ...   \nE014086.30.4 0.253165 0.127531 0.423113 0.068966     E014086           912   \nE014086.32.4 0.341772 0.345042 0.622876 0.285714     E014086           972   \nE014086.33.5 0.373418 0.537809 0.756436 0.507389     E014086          1005   \nE014086.34.4 0.316456 0.631597 0.749125 0.610837     E014086          1032   \nE014086.36.0 0.177215 0.488320 0.559266 0.443350     E014086          1080   \n\n              ind_time  \nE000823.4.0   4.000000  \nE000823.5.0   5.000000  \nE000823.5.7   5.700000  \nE000823.6.7   6.700000  \nE000823.8.5   8.500000  \n...                ...  \nE014086.30.4 30.400000  \nE014086.32.4 32.400000  \nE014086.33.5 33.500000  \nE014086.34.4 34.400000  \nE014086.36.0 36.000000  \n\n[519 rows x 205 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>659361</th>\n      <th>364179</th>\n      <th>3439402</th>\n      <th>181155</th>\n      <th>302746</th>\n      <th>4473763</th>\n      <th>175535</th>\n      <th>3887769</th>\n      <th>585227</th>\n      <th>189384</th>\n      <th>...</th>\n      <th>3304236</th>\n      <th>584137</th>\n      <th>193233</th>\n      <th>4334711</th>\n      <th>196664</th>\n      <th>583117</th>\n      <th>354850</th>\n      <th>subject_id</th>\n      <th>sampling_day</th>\n      <th>ind_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>E000823.4.0</th>\n      <td>0.000000</td>\n      <td>0.000160</td>\n      <td>0.288889</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.242718</td>\n      <td>0.010256</td>\n      <td>0.190476</td>\n      <td>0.000000</td>\n      <td>0.100671</td>\n      <td>...</td>\n      <td>0.029412</td>\n      <td>0.000000</td>\n      <td>0.040201</td>\n      <td>0.455696</td>\n      <td>0.059699</td>\n      <td>0.010154</td>\n      <td>0.064039</td>\n      <td>E000823</td>\n      <td>120</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>E000823.5.0</th>\n      <td>0.000000</td>\n      <td>0.000160</td>\n      <td>0.200000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.199029</td>\n      <td>0.007692</td>\n      <td>0.119048</td>\n      <td>0.000000</td>\n      <td>0.120805</td>\n      <td>...</td>\n      <td>0.117647</td>\n      <td>0.000000</td>\n      <td>0.035804</td>\n      <td>0.398734</td>\n      <td>0.054162</td>\n      <td>0.010779</td>\n      <td>0.029557</td>\n      <td>E000823</td>\n      <td>150</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>E000823.5.7</th>\n      <td>0.000000</td>\n      <td>0.000180</td>\n      <td>0.200000</td>\n      <td>0.003724</td>\n      <td>0.000000</td>\n      <td>0.228155</td>\n      <td>0.007692</td>\n      <td>0.023810</td>\n      <td>0.000000</td>\n      <td>0.053691</td>\n      <td>...</td>\n      <td>0.117647</td>\n      <td>0.000000</td>\n      <td>0.034338</td>\n      <td>0.518987</td>\n      <td>0.060045</td>\n      <td>0.009685</td>\n      <td>0.019704</td>\n      <td>E000823</td>\n      <td>171</td>\n      <td>5.700000</td>\n    </tr>\n    <tr>\n      <th>E000823.6.7</th>\n      <td>0.065636</td>\n      <td>0.000160</td>\n      <td>0.088889</td>\n      <td>0.016139</td>\n      <td>0.000000</td>\n      <td>0.121359</td>\n      <td>0.002564</td>\n      <td>0.023810</td>\n      <td>0.000000</td>\n      <td>0.080537</td>\n      <td>...</td>\n      <td>0.205882</td>\n      <td>0.000085</td>\n      <td>0.021566</td>\n      <td>0.386076</td>\n      <td>0.035127</td>\n      <td>0.006092</td>\n      <td>0.000000</td>\n      <td>E000823</td>\n      <td>201</td>\n      <td>6.700000</td>\n    </tr>\n    <tr>\n      <th>E000823.8.5</th>\n      <td>0.065636</td>\n      <td>0.000220</td>\n      <td>0.177778</td>\n      <td>0.017381</td>\n      <td>0.000000</td>\n      <td>0.490291</td>\n      <td>0.020513</td>\n      <td>0.071429</td>\n      <td>0.000000</td>\n      <td>0.053691</td>\n      <td>...</td>\n      <td>0.176471</td>\n      <td>0.000085</td>\n      <td>0.050251</td>\n      <td>0.386076</td>\n      <td>0.061602</td>\n      <td>0.037334</td>\n      <td>0.000000</td>\n      <td>E000823</td>\n      <td>255</td>\n      <td>8.500000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>E014086.30.4</th>\n      <td>0.060355</td>\n      <td>0.080890</td>\n      <td>0.288889</td>\n      <td>0.007449</td>\n      <td>0.044379</td>\n      <td>0.111650</td>\n      <td>0.025641</td>\n      <td>0.476190</td>\n      <td>0.479017</td>\n      <td>0.503356</td>\n      <td>...</td>\n      <td>0.470588</td>\n      <td>0.055292</td>\n      <td>0.091290</td>\n      <td>0.253165</td>\n      <td>0.127531</td>\n      <td>0.423113</td>\n      <td>0.068966</td>\n      <td>E014086</td>\n      <td>912</td>\n      <td>30.400000</td>\n    </tr>\n    <tr>\n      <th>E014086.32.4</th>\n      <td>0.060355</td>\n      <td>0.120524</td>\n      <td>0.622222</td>\n      <td>0.010552</td>\n      <td>0.077663</td>\n      <td>0.194175</td>\n      <td>0.071795</td>\n      <td>0.404762</td>\n      <td>0.880928</td>\n      <td>0.711409</td>\n      <td>...</td>\n      <td>0.441176</td>\n      <td>0.071990</td>\n      <td>0.142169</td>\n      <td>0.341772</td>\n      <td>0.345042</td>\n      <td>0.622876</td>\n      <td>0.285714</td>\n      <td>E014086</td>\n      <td>972</td>\n      <td>32.400000</td>\n    </tr>\n    <tr>\n      <th>E014086.33.5</th>\n      <td>0.051679</td>\n      <td>0.141802</td>\n      <td>1.000000</td>\n      <td>0.011173</td>\n      <td>0.161243</td>\n      <td>0.436893</td>\n      <td>0.074359</td>\n      <td>0.619048</td>\n      <td>0.849198</td>\n      <td>0.906040</td>\n      <td>...</td>\n      <td>0.264706</td>\n      <td>0.057024</td>\n      <td>0.213358</td>\n      <td>0.373418</td>\n      <td>0.537809</td>\n      <td>0.756436</td>\n      <td>0.507389</td>\n      <td>E014086</td>\n      <td>1005</td>\n      <td>33.500000</td>\n    </tr>\n    <tr>\n      <th>E014086.34.4</th>\n      <td>0.021124</td>\n      <td>0.127490</td>\n      <td>0.977778</td>\n      <td>0.004345</td>\n      <td>0.160503</td>\n      <td>0.572816</td>\n      <td>0.071795</td>\n      <td>0.571429</td>\n      <td>0.761174</td>\n      <td>0.899329</td>\n      <td>...</td>\n      <td>0.294118</td>\n      <td>0.037543</td>\n      <td>0.241625</td>\n      <td>0.316456</td>\n      <td>0.631597</td>\n      <td>0.749125</td>\n      <td>0.610837</td>\n      <td>E014086</td>\n      <td>1032</td>\n      <td>34.400000</td>\n    </tr>\n    <tr>\n      <th>E014086.36.0</th>\n      <td>0.010939</td>\n      <td>0.087755</td>\n      <td>0.755556</td>\n      <td>0.001862</td>\n      <td>0.130917</td>\n      <td>0.563107</td>\n      <td>0.023077</td>\n      <td>0.523810</td>\n      <td>0.295462</td>\n      <td>0.570470</td>\n      <td>...</td>\n      <td>0.352941</td>\n      <td>0.008463</td>\n      <td>0.217127</td>\n      <td>0.177215</td>\n      <td>0.488320</td>\n      <td>0.559266</td>\n      <td>0.443350</td>\n      <td>E014086</td>\n      <td>1080</td>\n      <td>36.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>519 rows × 205 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3514f91cd3c8ccb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T14:32:22.986909733Z",
     "start_time": "2023-10-06T14:32:22.982496290Z"
    }
   },
   "source": [
    "## Features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test subjects are ['E006493' 'E013094' 'E003188']\n"
     ]
    }
   ],
   "source": [
    "train_feats, train_targets, val_feats, val_targets, test_feats, test_targets, test_subjects = xgboost_flat_feats_and_targets(df, n_test_seq=number_test_sequences, seq_length=sequence_length)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:18:59.818976257Z",
     "start_time": "2023-10-30T18:18:56.310263625Z"
    }
   },
   "id": "e2b21c85db4ededf"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_feats, _, train_targets, _ = evalml.preprocessing.split_data(train_feats, train_targets, problem_type=\"regression\", test_size=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:19:01.353880568Z",
     "start_time": "2023-10-30T18:18:59.820018333Z"
    }
   },
   "id": "d8930b8dacc29ea3"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "        0        1        2        3        4        5        6        7     \\\n71  0.171633 0.003395 0.002641 0.002263 0.001132 0.004904 0.027914 0.110524   \n37  0.162580 0.166352 0.150132 0.050170 0.144474 0.143342 0.142588 0.027160   \n74  0.291965 0.309694 0.161449 0.133157 0.107129 0.483968 0.887212 1.000000   \n108 0.425500 0.379102 0.000377 0.000377 0.000000 0.002263 0.006413 0.132780   \n228 0.000000 0.000000 0.000000 0.000000 0.048284 0.176160 0.206714 0.271973   \n..       ...      ...      ...      ...      ...      ...      ...      ...   \n67  0.022256 0.022256 0.028668 0.006413 0.007167 0.018106 0.143342 0.262542   \n192 0.013580 0.013580 0.054319 0.042248 0.042248 0.000000 0.000377 0.000377   \n117 0.010939 0.000377 0.000000 0.000000 0.000377 0.000377 0.000377 0.002641   \n47  0.000000 0.068276 0.070162 0.070162 0.001886 0.000000 0.000000 0.000000   \n172 0.001886 0.001886 0.000000 0.000000 0.019238 0.019238 0.025273 0.006790   \n\n        8        9     ...      2030      2031      2032      2033      2034  \\\n71  0.107129 0.085251  ... 15.800000 16.900000 19.200000 20.000000 21.100000   \n37  0.042625 0.040739  ... 22.800000 23.600000 25.600000 26.900000 27.800000   \n74  0.783855 0.377593  ... 14.800000 15.700000 16.700000 17.800000 19.000000   \n108 0.160317 0.216899  ...  1.900000  3.100000  3.700000  4.900000  5.800000   \n228 0.188608 0.304791  ...  7.000000  8.400000  9.100000 10.300000 12.100000   \n..       ...      ...  ...       ...       ...       ...       ...       ...   \n67  0.265183 0.158054  ...  7.900000  8.900000  9.700000 10.700000 12.000000   \n192 0.000377 0.000377  ... 12.600000 13.500000 14.600000 15.600000 16.600000   \n117 0.004149 0.004149  ...  2.600000  3.700000  4.300000  5.700000  7.900000   \n47  0.000000 0.000000  ... 13.200000 14.900000 15.800000 18.000000 19.500000   \n172 0.007922 0.029423  ... 24.700000 25.700000 26.500000 27.300000 28.100000   \n\n         2035      2036      2037      2038      2039  \n71  22.500000 23.500000 24.800000 27.900000 29.000000  \n37  28.800000 29.800000 30.900000 33.000000 34.000000  \n74  19.700000 21.000000 22.700000 24.200000 24.900000  \n108  7.600000  8.000000  8.700000 10.000000 10.600000  \n228 13.100000 13.900000 15.400000 16.400000 17.100000  \n..        ...       ...       ...       ...       ...  \n67  13.800000 15.200000 15.800000 17.000000 18.000000  \n192 17.600000 18.400000 19.400000 20.400000 21.400000  \n117  8.500000  9.100000 10.500000 12.600000 13.600000  \n47  20.600000 21.700000 23.800000 25.500000 28.000000  \n172 29.100000 30.000000 31.400000 32.300000 33.500000  \n\n[240 rows x 2040 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>2030</th>\n      <th>2031</th>\n      <th>2032</th>\n      <th>2033</th>\n      <th>2034</th>\n      <th>2035</th>\n      <th>2036</th>\n      <th>2037</th>\n      <th>2038</th>\n      <th>2039</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>71</th>\n      <td>0.171633</td>\n      <td>0.003395</td>\n      <td>0.002641</td>\n      <td>0.002263</td>\n      <td>0.001132</td>\n      <td>0.004904</td>\n      <td>0.027914</td>\n      <td>0.110524</td>\n      <td>0.107129</td>\n      <td>0.085251</td>\n      <td>...</td>\n      <td>15.800000</td>\n      <td>16.900000</td>\n      <td>19.200000</td>\n      <td>20.000000</td>\n      <td>21.100000</td>\n      <td>22.500000</td>\n      <td>23.500000</td>\n      <td>24.800000</td>\n      <td>27.900000</td>\n      <td>29.000000</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.162580</td>\n      <td>0.166352</td>\n      <td>0.150132</td>\n      <td>0.050170</td>\n      <td>0.144474</td>\n      <td>0.143342</td>\n      <td>0.142588</td>\n      <td>0.027160</td>\n      <td>0.042625</td>\n      <td>0.040739</td>\n      <td>...</td>\n      <td>22.800000</td>\n      <td>23.600000</td>\n      <td>25.600000</td>\n      <td>26.900000</td>\n      <td>27.800000</td>\n      <td>28.800000</td>\n      <td>29.800000</td>\n      <td>30.900000</td>\n      <td>33.000000</td>\n      <td>34.000000</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>0.291965</td>\n      <td>0.309694</td>\n      <td>0.161449</td>\n      <td>0.133157</td>\n      <td>0.107129</td>\n      <td>0.483968</td>\n      <td>0.887212</td>\n      <td>1.000000</td>\n      <td>0.783855</td>\n      <td>0.377593</td>\n      <td>...</td>\n      <td>14.800000</td>\n      <td>15.700000</td>\n      <td>16.700000</td>\n      <td>17.800000</td>\n      <td>19.000000</td>\n      <td>19.700000</td>\n      <td>21.000000</td>\n      <td>22.700000</td>\n      <td>24.200000</td>\n      <td>24.900000</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>0.425500</td>\n      <td>0.379102</td>\n      <td>0.000377</td>\n      <td>0.000377</td>\n      <td>0.000000</td>\n      <td>0.002263</td>\n      <td>0.006413</td>\n      <td>0.132780</td>\n      <td>0.160317</td>\n      <td>0.216899</td>\n      <td>...</td>\n      <td>1.900000</td>\n      <td>3.100000</td>\n      <td>3.700000</td>\n      <td>4.900000</td>\n      <td>5.800000</td>\n      <td>7.600000</td>\n      <td>8.000000</td>\n      <td>8.700000</td>\n      <td>10.000000</td>\n      <td>10.600000</td>\n    </tr>\n    <tr>\n      <th>228</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.048284</td>\n      <td>0.176160</td>\n      <td>0.206714</td>\n      <td>0.271973</td>\n      <td>0.188608</td>\n      <td>0.304791</td>\n      <td>...</td>\n      <td>7.000000</td>\n      <td>8.400000</td>\n      <td>9.100000</td>\n      <td>10.300000</td>\n      <td>12.100000</td>\n      <td>13.100000</td>\n      <td>13.900000</td>\n      <td>15.400000</td>\n      <td>16.400000</td>\n      <td>17.100000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>67</th>\n      <td>0.022256</td>\n      <td>0.022256</td>\n      <td>0.028668</td>\n      <td>0.006413</td>\n      <td>0.007167</td>\n      <td>0.018106</td>\n      <td>0.143342</td>\n      <td>0.262542</td>\n      <td>0.265183</td>\n      <td>0.158054</td>\n      <td>...</td>\n      <td>7.900000</td>\n      <td>8.900000</td>\n      <td>9.700000</td>\n      <td>10.700000</td>\n      <td>12.000000</td>\n      <td>13.800000</td>\n      <td>15.200000</td>\n      <td>15.800000</td>\n      <td>17.000000</td>\n      <td>18.000000</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>0.013580</td>\n      <td>0.013580</td>\n      <td>0.054319</td>\n      <td>0.042248</td>\n      <td>0.042248</td>\n      <td>0.000000</td>\n      <td>0.000377</td>\n      <td>0.000377</td>\n      <td>0.000377</td>\n      <td>0.000377</td>\n      <td>...</td>\n      <td>12.600000</td>\n      <td>13.500000</td>\n      <td>14.600000</td>\n      <td>15.600000</td>\n      <td>16.600000</td>\n      <td>17.600000</td>\n      <td>18.400000</td>\n      <td>19.400000</td>\n      <td>20.400000</td>\n      <td>21.400000</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>0.010939</td>\n      <td>0.000377</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000377</td>\n      <td>0.000377</td>\n      <td>0.000377</td>\n      <td>0.002641</td>\n      <td>0.004149</td>\n      <td>0.004149</td>\n      <td>...</td>\n      <td>2.600000</td>\n      <td>3.700000</td>\n      <td>4.300000</td>\n      <td>5.700000</td>\n      <td>7.900000</td>\n      <td>8.500000</td>\n      <td>9.100000</td>\n      <td>10.500000</td>\n      <td>12.600000</td>\n      <td>13.600000</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.000000</td>\n      <td>0.068276</td>\n      <td>0.070162</td>\n      <td>0.070162</td>\n      <td>0.001886</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>13.200000</td>\n      <td>14.900000</td>\n      <td>15.800000</td>\n      <td>18.000000</td>\n      <td>19.500000</td>\n      <td>20.600000</td>\n      <td>21.700000</td>\n      <td>23.800000</td>\n      <td>25.500000</td>\n      <td>28.000000</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>0.001886</td>\n      <td>0.001886</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.019238</td>\n      <td>0.019238</td>\n      <td>0.025273</td>\n      <td>0.006790</td>\n      <td>0.007922</td>\n      <td>0.029423</td>\n      <td>...</td>\n      <td>24.700000</td>\n      <td>25.700000</td>\n      <td>26.500000</td>\n      <td>27.300000</td>\n      <td>28.100000</td>\n      <td>29.100000</td>\n      <td>30.000000</td>\n      <td>31.400000</td>\n      <td>32.300000</td>\n      <td>33.500000</td>\n    </tr>\n  </tbody>\n</table>\n<p>240 rows × 2040 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:19:01.365823524Z",
     "start_time": "2023-10-30T18:19:01.362041209Z"
    }
   },
   "id": "c2e7d1c480294453"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to properly train an XGBoost model we need a proper validation set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca39d75895284351"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a7b33c9deb7b130"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                         n_estimators=10, \n",
    "                         max_leaves=100,\n",
    "                         max_depth=100,  \n",
    "                         n_jobs=50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T18:19:01.446043131Z",
     "start_time": "2023-10-30T18:19:01.365967096Z"
    }
   },
   "id": "e9b66db6f530e329"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.fit(train_feats, train_targets, eval_set=[(val_feats, val_targets)], verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-30T18:19:01.433360272Z"
    }
   },
   "id": "46419bad557fa604"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d52d564d6b3dc594"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_subjects"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "df8b8eeb40c8e6ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target_subject_idx = 0\n",
    "target_subject = test_subjects[target_subject_idx]\n",
    "\n",
    "subject_feats = test_feats[target_subject]\n",
    "subject_targets = test_targets[target_subject]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "78aaf74b2c9177cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subject_feats, _, subject_targets, _ = evalml.preprocessing.split_data(subject_feats, subject_targets, problem_type=\"regression\", test_size=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a34c1fcca6aba0b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subject_targets"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a79fcc8a78b81453"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(model.predict(subject_feats))\n",
    "pred_df.columns = subject_targets.columns\n",
    "pred_df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9cbb05555a4f965e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_targets[target_subject]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4d973b1ed95a8367"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b555189d33d991f1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fetch_subject_y_true_and_y_pred(test_subjects, model, df, target_subject_idx, test_feats, test_targets):\n",
    "    \n",
    "    cols = df.columns\n",
    "    cols = cols[~cols.isin(ignore_cols)]\n",
    "    \n",
    "    target_subject = test_subjects[target_subject_idx]\n",
    "\n",
    "    test_subject_feats = np.asarray(test_feats[target_subject])\n",
    "    test_subject_targets_df = test_targets[target_subject]\n",
    "    \n",
    "    test_subject_targets_df.columns = cols\n",
    "    test_subject_y_pred = model.predict(test_subject_feats)\n",
    "    \n",
    "    test_subject_y_pred_df = pd.DataFrame(test_subject_y_pred)\n",
    "    test_subject_y_pred_df.columns = cols\n",
    "    test_subject_y_pred_df.index = test_subject_targets_df.index\n",
    "\n",
    "    return test_subject_targets_df, test_subject_y_pred_df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "fa34cbac94ca9043"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3ee334699c1f1",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "subjects_error_dfs = []\n",
    "for target_subject_idx in range(len(test_subjects)):\n",
    "    \n",
    "    test_subject_targets_df, test_subject_y_pred_df = fetch_subject_y_true_and_y_pred(test_subjects, model, df, target_subject_idx, test_feats, test_targets)\n",
    "\n",
    "    errors_df = calculate_percentage_errors(test_subject_y_pred_df, test_subject_targets_df)\n",
    "    subjects_error_dfs.append(errors_df)\n",
    "    \n",
    "errors_df = pd.concat(subjects_error_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "percentile_graph(errors_df, \"accross all taxa XGBOOST\", y_top_lim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "22f41ad4cd010943"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f17dfdedeb5f3ba5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
